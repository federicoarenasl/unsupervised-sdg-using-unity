{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "- We'll look at geomloss and MMD loss function, InceptionV3 and how to train only the last layer \n",
    "- Second part will be training an MMD GAN, where we replace the InceptionV3 network and Renderer with a classical Discriminator - Generator Convolutional Architecture \n",
    "- We need to install geomloss from the latest master branch, I'm not confident that we'll get the best results if we just do pip install. \n",
    "\n",
    "## Pending Questions (in no particular order) \n",
    "- Does the original MetaSim train the last layer of the InceptionV3 network or does it keep the whole network frozen? during the GCN learning phase?  \n",
    "- Can we learn with an MMD GAN to generate images that look like the target images, and have a sanity check that the MMD distance is indeed what we should be using (I'm not sure how valid this experiment is, since we're changing the architecture and essentially changing the problem. But it's good to test that we're doing the right thing in terms of workflow. \n",
    "- What resolution should we generate the synthetic images (target/source)? Original InceptionV3 expects 299x299 unless there's some re-writeup of the original one in MetaSim. Whatever resolution it is, it should be bigger than 299x299 and we can resize at loading time with torchvision.transforms\n",
    "- What normalization should we apply at load time on the image? Since InceptionV3 is pre-trained on ImageNet, I believe it should be the right mean and std of ImageNet. Same for test time normalization. \n",
    "- What is a good size of the last layer? Since we have no classes, we can have 100 nodes or 1000. This will probably also be driven by OOM problems \n",
    "- Do we fix the OOM problems and how fast the MMD works if we move to SamplesLoss? Can we use batch_size = 100 and images of high enough resolution? I believe the OOM problems are related to how many images we're trying to fit into a batch, not with the actual computation. \n",
    "\n",
    "## InceptionV3\n",
    "https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "## Using GeomLoss on sampled 10-D measures (distributions) \n",
    " - you first have to \"create\" two distributions that you want to compare\n",
    " - I will use multivariate gaussians, instead of 1-D gaussians, since this is what we have if we move to images. \n",
    " - for example, I have created two gaussians: \n",
    "     - they can be fully specified by their mean and variance \n",
    "     - they can also be specified by sampling from them, which is more in line with what we have. \n",
    " - you can think of images as samples from some unknown data distribution \n",
    " - this loss function then allows you to compare two distributions, by comparing their samples. The more samples you have, the more accurate the comparison. \n",
    " - we'll use the \"energy\" kernel and the \"gaussian\" kernel or the \"laplacian\" kernels \n",
    " - see this [nice post](https://stats.stackexchange.com/questions/276497/maximum-mean-discrepancy-distance-distribution) about MMD and kernels \n",
    " - a lot more theoretical is [page 97 of this PHD thesis (Author of geomloss)](https://www.jeanfeydy.com/geometric_data_analysis.pdf)\n",
    " \n",
    " *Ref from the library: https://www.kernel-operations.io/geomloss/api/pytorch-api.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set_style('whitegrid')\n",
    "from pathlib import Path\n",
    "sys.path.append(\"..\")\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.metrics.pairwise import rbf_kernel, euclidean_distances\n",
    "import random\n",
    "import matplotlib.pylab as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "\n",
    "# Torch Dataset & Utils\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Optimizer, Functions, Distributions\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch import nn \n",
    "import torch.distributions as ds\n",
    "import torchvision.utils as vutils\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "import geomloss\n",
    "from geomloss import SamplesLoss\n",
    "# SRW imports from nldr\n",
    "# from nldr.datasets.synthetic import GaussianDataset\n",
    "\n",
    "# Useful\n",
    "get_types = lambda x :[(a, getattr(x, a)) for a in dir(x) if not callable(getattr(x, a)) and a[0] != '_']\n",
    "\n",
    "# Change this to run locally \n",
    "parent_dir = \"/home/federicoarenasl/Documents/Federico/UoE/MSC_AI/Thesis_project/implementation/meta-sim/custom-sim/data/geomloss/high_res/unity\"\n",
    "source_images_0 = os.path.join(parent_dir, \"prior/0\")\n",
    "source_images_15 = os.path.join(parent_dir, \"prior/15\")\n",
    "source_images_45 = os.path.join(parent_dir, \"prior/45\")\n",
    "source_images_90 = os.path.join(parent_dir, \"prior/90\")\n",
    "target_images = os.path.join(parent_dir, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy = lambda x : x.detach().cpu().numpy()\n",
    "transpose = lambda x: np.transpose(numpy(x), (1, 2, 0))\n",
    "positive = lambda x: [np.abs(a) for a in x]\n",
    "gpu = torch.cuda.is_available()\n",
    "device = None\n",
    "if gpu:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD between Image samples \n",
    "   - Step 1: Create a torch Dataset and DataLoaders for our datasets, so we can sample \n",
    "   - Step 2: Use an \"encoder\" to push images from 32x32 to size 10 and compute MMD in the \"feature\" space \n",
    "   - Step 4: Train a GAN MMD to \"generate\" samples that look like the target samples. \n",
    "   - Step 5: Replace GAN MMD with a renderer and use only the \"encoder\" part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.io import read_image\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "class ShoeDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms=None):\n",
    "\n",
    "        super(ShoeDataset, self).__init__()\n",
    "        self.root = Path(root)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.imgs_path = sorted([file for file in self.root.iterdir()]) \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        # Load Image\n",
    "        img_path = self.root / self.imgs_path[idx]\n",
    "        \n",
    "        #read_image(str(img_path))\n",
    "        orig_img = Image.open(str(img_path)).convert(\"RGB\")\n",
    "        #image_np = np.asarray(orig_img).astype(np.float32)\n",
    "        \n",
    "        if self.transforms:\n",
    "            #return self.augmentations(image=image_np)['image'], label\n",
    "            return self.transforms(orig_img)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "# We should generate images that are big, but resize them to Inception scale before using the model \n",
    "# We don't want to upscale the images \n",
    "# **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "# N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "\n",
    "IMAGE_SIZE_INCEPTION = 299 \n",
    "shoe_transformer = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize(IMAGE_SIZE_INCEPTION),\n",
    "                               #torchvision.transforms.CenterCrop(IMAGE_SIZE),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               #torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                             ])\n",
    "default_transformer = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset_0 = ShoeDataset(root = source_images_0, transforms = shoe_transformer)\n",
    "target_dataset = ShoeDataset(root = target_images, transforms = shoe_transformer)\n",
    "\n",
    "# Assign batch size the whole dataset \n",
    "bs_source_0 = len(source_dataset_0)\n",
    "bs_target = len(target_dataset)\n",
    "\n",
    "source_loader_0 = DataLoader(source_dataset_0, batch_size = bs_source_0, shuffle = True, drop_last=False)\n",
    "source_loader_15 = DataLoader(source_dataset_0, batch_size = bs_source_0, shuffle = True, drop_last=False)\n",
    "source_loader_45 = DataLoader(source_dataset_0, batch_size = bs_source_0, shuffle = True, drop_last=False)\n",
    "source_loader_90 = DataLoader(source_dataset_0, batch_size = bs_source_0, shuffle = True, drop_last=False)\n",
    "target_loader = DataLoader(target_dataset, batch_size = bs_target, shuffle = True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = iter(source_loader_0).next()\n",
    "X2 = iter(target_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 299, 299]) torch.Size([100, 3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape, X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(transpose(X1[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we set transform_input to True, it will normalize the images according to the ImageNet training  \n",
    "# See https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# Inception V3 always needs 299 as input size, so when you go from 32x32 to 299, you do upsampling which is no no. \n",
    "# https://pytorch.org/vision/stable/_modules/torchvision/models/inception.html\n",
    "model_inception = models.inception_v3(pretrained=True, transform_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auxiliary net \n",
    "model_inception.AuxLogits.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primary net\n",
    "model_inception.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 299\n",
    "# Set output layer to 100 because why not \n",
    "out_features = 100 \n",
    "\n",
    "# When feature_extract is True, you only train the very last layer! Super important and useful! \n",
    "set_parameter_requires_grad(model_inception, feature_extract=True)\n",
    "\n",
    "# Handle the auxilary net\n",
    "model_inception.AuxLogits.fc = nn.Linear(768, out_features)\n",
    "\n",
    "# Handle the primary net\n",
    "model_inception.fc = nn.Linear(2048,out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=100, bias=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inception.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=100, bias=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inception.AuxLogits.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 299, 299])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_X1, aux_outputs_X1 = model_inception(X1) # shape batch_size = 100, outdim = 100 \n",
    "out_features_X2, aux_outputs_X2 = model_inception(X2) # shape batch_size = 100, out_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_features_X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0101,  0.3206,  0.0972,  ...,  0.2486, -0.1927, -0.1044],\n",
       "        [ 0.3984,  0.0643, -0.0774,  ...,  0.3320, -0.3805, -0.0983],\n",
       "        [-0.0729,  0.0395, -0.1674,  ...,  0.3201,  0.0305,  0.1747],\n",
       "        ...,\n",
       "        [-0.0713, -0.2683,  0.3195,  ...,  0.0904, -0.4413,  0.2400],\n",
       "        [ 0.1190, -0.0522, -0.0594,  ...,  0.1513, -0.4681, -0.2497],\n",
       "        [-0.1271,  0.1283,  0.1370,  ...,  0.0286, -0.0078,  0.0706]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_features_X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD Energy between feature space is:  tensor(0.0157)\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the features, we get an instant result for the MMD :) \n",
    "print(\"MMD Energy between feature space is: \", loss_mmd_gaussian(outputs_X1, out_features_X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD Energy between feature space is:  tensor(0.0336)\n"
     ]
    }
   ],
   "source": [
    "print(\"MMD Energy between feature space is: \", loss_mmd_energy(outputs_X1, out_features_X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: During training, we have to create two losses for the InceptionV3, based on the two heads the network has. At test time we only use the main network head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is:  tensor(0.1829)\n"
     ]
    }
   ],
   "source": [
    "# Combine losses from outputs and auxiliary outputs\n",
    "loss1 = loss_mmd_gaussian(outputs_X1, out_features_X2)\n",
    "loss2 = loss_mmd_gaussian(aux_outputs_X1, aux_outputs_X2)\n",
    "loss = loss1 + 0.4*loss2\n",
    "print(\"Final loss is: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('metasim': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd01381974e8240e6182900334f3d89a6675614ed41eccefd705451eb79e2d827cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
